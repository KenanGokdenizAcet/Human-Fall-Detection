{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "import mediapipe as mp\n",
    "import warnings \n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def image_to_video(input_path, output_path, fps=18):\n",
    "    images = sorted(glob.glob(os.path.join(input_path, '*.png'))) # Sort the images in ascending order\n",
    "\n",
    "    frame = cv2.imread(images[0])\n",
    "    height, width, layers = frame.shape\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    \n",
    "    video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    for image in images:\n",
    "        video.write(cv2.imread(image))\n",
    "    \n",
    "    video.release()\n",
    "    \n",
    "    print(\"\"\"Video saved as {}\"\"\".format(output_path))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76ed2ed414722e3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def concat_csv_files(input_folder):\n",
    "    combined_df = pd.DataFrame()\n",
    "    sorted_files = sorted(glob.glob(os.path.join(input_folder, '*.csv')))\n",
    "    for file in sorted_files:\n",
    "        df = pd.read_csv(file)\n",
    "        combined_df = pd.concat([combined_df, df[4:]], ignore_index=True)\n",
    "    \n",
    "    return combined_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b020e5c9769a0cd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Create sequences with a fixed window size\n",
    "def create_sequences(X, y, window_size):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - window_size):\n",
    "        Xs.append(X[i:i+window_size])\n",
    "        ys.append(y[i+window_size])\n",
    "    return np.array(Xs), np.array(ys)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65f6b0f155f7dee0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "class LSTMModel:\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(LSTM(64, input_shape=input_shape, return_sequences=True))\n",
    "        self.model.add(Dropout(0.2))\n",
    "        self.model.add(LSTM(32))\n",
    "        self.model.add(Dropout(0.2))\n",
    "        self.model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    def compile(self):\n",
    "        self.model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def summary(self):\n",
    "        return self.model.summary()\n",
    "    \n",
    "    def fit(self, X_seq, y_seq, epochs=10, batch_size=32, validation_split=0.2, shuffle=True):\n",
    "        return self.model.fit(X_seq, y_seq, epochs=epochs, batch_size=batch_size, validation_split=validation_split, shuffle=shuffle)\n",
    "    \n",
    "    def evaluate(self, X_seq, y_seq):\n",
    "        return self.model.evaluate(X_seq, y_seq)\n",
    "    \n",
    "    def predict(self, X_seq):\n",
    "        return self.model.predict(X_seq)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f541e5a1ffa7b41c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def feature_posses_from_frame(results, mp_pose, frame_count):\n",
    "    df = []\n",
    "    \n",
    "    main_column_names = [\n",
    "        'head_x',\n",
    "        'head_y',\n",
    "        'l_shoulder_x',\n",
    "        'l_shoulder_y',\n",
    "        'l_belly_x',\n",
    "        'l_belly_y',\n",
    "        'l_knee_x',\n",
    "        'l_knee_y',\n",
    "        'r_shoulder_x',\n",
    "        'r_shoulder_y',\n",
    "        'r_belly_x',\n",
    "        'r_belly_y',\n",
    "        'r_knee_x',\n",
    "        'r_knee_y']\n",
    "\n",
    "    if results.pose_landmarks is not None:\n",
    "        # Extract key points\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "        # Get coordinates of head, shoulder, belly, and knees\n",
    "        head_x = landmarks[mp_pose.PoseLandmark.NOSE.value].x\n",
    "        head_y = landmarks[mp_pose.PoseLandmark.NOSE.value].y\n",
    "\n",
    "        l_shoulder_x = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x\n",
    "        l_shoulder_y = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y\n",
    "        l_belly_x = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x\n",
    "        l_belly_y = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y\n",
    "        l_knee_x = landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x\n",
    "        l_knee_y = landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y\n",
    "\n",
    "        r_shoulder_x = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x\n",
    "        r_shoulder_y = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y\n",
    "        r_belly_x = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x\n",
    "        r_belly_y = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y\n",
    "        r_knee_x = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x\n",
    "        r_knee_y = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y\n",
    "\n",
    "        df.append({'frame': frame_count,\n",
    "                   'head_x': head_x,\n",
    "                   'head_y': head_y,\n",
    "                   'l_shoulder_x': l_shoulder_x,\n",
    "                   'l_shoulder_y': l_shoulder_y,\n",
    "                   'l_belly_x': l_belly_x,\n",
    "                   'l_belly_y': l_belly_y,\n",
    "                   'l_knee_x': l_knee_x,\n",
    "                   'l_knee_y': l_knee_y,\n",
    "                   'r_shoulder_x': r_shoulder_x,\n",
    "                   'r_shoulder_y': r_shoulder_y,\n",
    "                   'r_belly_x': r_belly_x,\n",
    "                   'r_belly_y': r_belly_y,\n",
    "                   'r_knee_x': r_knee_x,\n",
    "                   'r_knee_y': r_knee_y})\n",
    "\n",
    "        df = pd.DataFrame(df)\n",
    "\n",
    "        # adding new columns for difference of previous frames\n",
    "        for i in range(4):\n",
    "            for col in main_column_names:\n",
    "                new_column_name = f'{col}diff_{i + 1}frame_before'\n",
    "                df[new_column_name] = np.nan\n",
    "\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fae47e81a326428",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def test_video(input_path, output_path, model):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    \n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose()\n",
    "    \n",
    "    frame_queue = []\n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    final_data_frame = pd.DataFrame()\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    \n",
    "    output_video = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert frame to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect pose\n",
    "        results = pose.process(rgb_frame)\n",
    "        \n",
    "        if results.pose_landmarks is not None:\n",
    "            # Extract key points\n",
    "            df = feature_posses_from_frame(results, mp_pose, frame_count)\n",
    "            \n",
    "            main_column_names = [\n",
    "                'head_x',\n",
    "                'head_y',\n",
    "                'l_shoulder_x',\n",
    "                'l_shoulder_y',\n",
    "                'l_belly_x',\n",
    "                'l_belly_y',\n",
    "                'l_knee_x',\n",
    "                'l_knee_y',\n",
    "                'r_shoulder_x',\n",
    "                'r_shoulder_y',\n",
    "                'r_belly_x',\n",
    "                'r_belly_y',\n",
    "                'r_knee_x',\n",
    "                'r_knee_y']\n",
    "            \n",
    "            \n",
    "            # adding previous frames information to the current frame feature matrix\n",
    "            if len(frame_queue) <= 4:\n",
    "                for i in range(min(len(frame_queue), 4)):\n",
    "                    for col in main_column_names:\n",
    "                        df[f\"{col}diff_{i + 1}frame_before\"] = df[col] - frame_queue[-(i + 1)][col]\n",
    "                frame_queue.append(df)\n",
    "            else:\n",
    "                frame_queue.pop(0)\n",
    "                for i in range(4):\n",
    "                    for col in main_column_names:\n",
    "                        df[f\"{col}diff_{i + 1}frame_before\"] = df[col] - frame_queue[-(i + 1)][col]\n",
    "                frame_queue.append(df)\n",
    "\n",
    "            final_data_frame = pd.concat([final_data_frame, df], ignore_index=True, sort=False)\n",
    "\n",
    "         \n",
    "            features = np.array(df)\n",
    "    \n",
    "            features = loaded_scaler.transform(features)\n",
    "            \n",
    "            seq = []\n",
    "    \n",
    "            seq.append(features)\n",
    "            seq = np.array(seq)\n",
    "            prediction = model.predict(seq)\n",
    "            prediction = np.argmax(prediction)\n",
    "            preds.append(prediction)\n",
    "            \n",
    "            if len(frame_queue) <= 4:\n",
    "                label = \"NO PREDICTION\"\n",
    "            elif prediction == 0:\n",
    "                label = \"FELL\"\n",
    "            elif prediction == 1:\n",
    "                label = \"IDLE\"\n",
    "            elif prediction == 2:\n",
    "                label = \"FALLING\"\n",
    "            \n",
    "            \n",
    "            cv2.putText(frame, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            output_video.write(frame)\n",
    "            \n",
    "            frame_count += 1\n",
    "    \n",
    "    \n",
    "    cap.release()\n",
    "    output_video.release()\n",
    "    \n",
    "    final_data_frame.to_csv(f'{input_path}.csv', index=False)\n",
    "    \n",
    "    return preds\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abb6d299088d24cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# getting train data\n",
    "dataset = concat_csv_files(\"train\")\n",
    "\n",
    "X = dataset.drop(\"label\", axis=1).values\n",
    "y = dataset[\"label\"].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "y = to_categorical(y+1)\n",
    "\n",
    "\n",
    "# save scaler\n",
    "joblib.dump(scaler, 'scaler_params.pkl')\n",
    "\n",
    "# load scaler\n",
    "loaded_scaler = joblib.load('scaler_params.pkl')\n",
    "\n",
    "X_seq, y_seq = create_sequences(X, y, 9)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e5c90fd196827ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings('ignore') \n",
    "model = LSTMModel((X_seq.shape[1], X_seq.shape[2]), 3)\n",
    "model.compile()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee5f81e19c18201d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model.fit(X_seq, y_seq, epochs=100, batch_size=128, validation_split=0.2, shuffle=True)\n",
    "model.model.save('model_saved.keras')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a229a5e5cecf0ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "loaded_model=load_model(\"model_saved.keras\")\n",
    "prediction=test_video(\"camera2.mp4\", \"output2.mp4\", loaded_model)\n"
   ],
   "id": "e359a6176016b80",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
